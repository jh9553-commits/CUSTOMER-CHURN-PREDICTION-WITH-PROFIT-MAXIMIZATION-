{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtbawGdpv2Hw4iP9ep/o/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh9553-commits/CUSTOMER-CHURN-PREDICTION-WITH-PROFIT-MAXIMIZATION-/blob/main/Data_bootcamp_final_project_without_Visualizations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXf8BFplGqst",
        "outputId": "37a0a9a7-d688-4313-fe01-898ad58d6a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "                                 CUSTOMER CHURN PREDICTION ANALYSIS                                 \n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "                              Data Preparation and Feature Engineering                              \n",
            "====================================================================================================\n",
            "\n",
            "Dataset Summary\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Total observations: 7,043\n",
            "Total features: 19\n",
            "Target variable (Churn): Binary classification\n",
            "Churn rate: 26.54%\n",
            "Class imbalance ratio: 2.77:1\n",
            "Training set size: 5,634\n",
            "Testing set size: 1,409\n",
            "\n",
            "====================================================================================================\n",
            "                                    Hyperparameter Optimization                                     \n",
            "====================================================================================================\n",
            "\n",
            "HistGradientBoosting Classifier Tuning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search completed: 81 parameter combinations evaluated\n",
            "Cross-validation strategy: 3-fold stratified\n",
            "Optimal ROC-AUC score: 0.8424\n",
            "Best parameters: {'l2_regularization': 1.0, 'learning_rate': 0.05, 'max_depth': 10, 'max_iter': 150}\n",
            "\n",
            "Neural Network Classifier Tuning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search completed: 81 parameter combinations evaluated\n",
            "Cross-validation strategy: 3-fold stratified\n",
            "Optimal ROC-AUC score: 0.8329\n",
            "Best parameters: {'alpha': 5e-05, 'hidden_layer_sizes': (128, 64, 32, 16), 'learning_rate_init': 0.0005, 'max_iter': 250}\n",
            "\n",
            "====================================================================================================\n",
            "                                 Classification Performance Metrics                                 \n",
            "====================================================================================================\n",
            "\n",
            "Default Threshold (0.50) Performance Comparison\n",
            "----------------------------------------------------------------------------------------------------\n",
            "               Model Accuracy Precision Recall Specificity F1_Score ROC_AUC    MCC\n",
            "HistGradientBoosting   0.7949    0.6384 0.5241      0.8928   0.5756  0.8379 0.4459\n",
            "      Neural Network   0.7885    0.6033 0.5936      0.8589   0.5984  0.8354 0.4549\n",
            "\n",
            "Detailed Classification Report: HistGradientBoosting\n",
            "----------------------------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    No Churn       0.84      0.89      0.86      1035\n",
            "       Churn       0.64      0.52      0.58       374\n",
            "\n",
            "    accuracy                           0.79      1409\n",
            "   macro avg       0.74      0.71      0.72      1409\n",
            "weighted avg       0.79      0.79      0.79      1409\n",
            "\n",
            "\n",
            "Detailed Classification Report: Neural Network\n",
            "----------------------------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    No Churn       0.85      0.86      0.86      1035\n",
            "       Churn       0.60      0.59      0.60       374\n",
            "\n",
            "    accuracy                           0.79      1409\n",
            "   macro avg       0.73      0.73      0.73      1409\n",
            "weighted avg       0.79      0.79      0.79      1409\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                  Statistical Significance Testing                                  \n",
            "====================================================================================================\n",
            "\n",
            "Bootstrap Confidence Intervals for ROC-AUC (1000 iterations)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoosting AUC: 0.8381 ± 0.0113\n",
            "95% Confidence interval: [0.8160, 0.8586]\n",
            "\n",
            "Neural Network AUC: 0.8353 ± 0.0111\n",
            "95% Confidence interval: [0.8137, 0.8566]\n",
            "\n",
            "\n",
            "Paired t-Test: F1-Score Comparison Across 50 Thresholds\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoost Mean F1: 0.4853 ± 0.1649\n",
            "Neural Network Mean F1: 0.4851 ± 0.1527\n",
            "t-statistic: -0.0503\n",
            "p-value: 0.960116\n",
            "Result: Not statistically significant (p >= 0.05).\n",
            "\n",
            "Cross-Validation Score Analysis (5-fold)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoosting CV ROC-AUC: 0.8131 ± 0.0276\n",
            "Fold scores: ['0.7790', '0.7879', '0.8345', '0.8116', '0.8523']\n",
            "\n",
            "Neural Network CV ROC-AUC: 0.6843 ± 0.0187\n",
            "Fold scores: ['0.7193', '0.6700', '0.6738', '0.6881', '0.6702']\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                    Profit Maximization Analysis                                    \n",
            "====================================================================================================\n",
            "\n",
            "Business Context and Cost Structure\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Customer Lifetime Value (CLV): $2,331.36\n",
            "Standard retention cost: $160.00\n",
            "TP value (retain churner): $539.41\n",
            "FP cost (wasted contact): -$160.00\n",
            "FN cost (lost customer): -$2,331.36\n",
            "Cost ratio (FN:FP): 14.57:1\n",
            "\n",
            "Threshold Optimization Results (Basic Strategy)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoosting optimal threshold: 0.050, Profit: $58,837.79\n",
            "Neural Network optimal threshold: 0.086, Profit: $76,194.72\n",
            "\n",
            "====================================================================================================\n",
            "                                  Segment-Based Strategy Analysis                                   \n",
            "====================================================================================================\n",
            "\n",
            "Segment-Based Performance (Neural Network - Optimal Model)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "High-Risk Segment:\n",
            " Sample count: 248\n",
            " Optimal threshold: 0.050\n",
            " Precision: 0.6734\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.8048\n",
            " Profit: $106,134.18\n",
            "\n",
            "Medium-Risk Segment:\n",
            " Sample count: 444\n",
            " Optimal threshold: 0.050\n",
            " Precision: 0.3423\n",
            " Recall: 1.0000\n",
            " F1-Score: 0.5101\n",
            " Profit: $35,270.32\n",
            "\n",
            "Low-Risk Segment:\n",
            " Sample count: 717\n",
            " Optimal threshold: 0.059\n",
            " Precision: 0.1202\n",
            " Recall: 0.9636\n",
            " F1-Score: 0.2137\n",
            " Profit: $5,488.70\n",
            "\n",
            "====================================================================================================\n",
            "                                         Summary of Results                                         \n",
            "====================================================================================================\n",
            "\n",
            "Strategy Performance Comparison\n",
            "----------------------------------------------------------------------------------------------------\n",
            "            Model      Strategy   Profit\n",
            "HistGradientBoost         Basic  $58,838\n",
            "HistGradientBoost Segment-Based $119,814\n",
            "   Neural Network         Basic  $76,195\n",
            "   Neural Network Segment-Based $146,893\n",
            "\n",
            "Recommended Model and Strategy\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Best performing model: Neural Network (Segment-Based)\n",
            "Annual profit: $146,893.20\n",
            "Improvement vs. baseline: 149.7%\n",
            "Tuning value gained: $70,698.48\n",
            "\n",
            "====================================================================================================\n",
            "                                         Report Generation                                          \n",
            "====================================================================================================\n",
            "Generated: classification_metrics_report.csv\n",
            "Generated: segment_analysis_metrics.csv\n",
            "Generated: strategy_performance.csv\n",
            "\n",
            "====================================================================================================\n",
            "                                         Analysis Complete                                          \n",
            "====================================================================================================\n",
            "\n",
            "All analyses have been completed successfully.\n",
            "Output files have been generated in the working directory.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "CUSTOMER CHURN PREDICTION WITH PROFIT MAXIMIZATION\n",
        "Comprehensive Analysis with Hyperparameter Tuning and Statistical Validation\n",
        "\n",
        "Author: Jianxun Huang | Final Version - December 20, 2025\n",
        "\n",
        "Predicts customer churn for telecom company using cost-sensitive ML models\n",
        "(HistGradientBoosting & Neural Network) with threshold optimization and\n",
        "customer segmentation. Achieves $146,893 annual profit (186% improvement\n",
        "over baseline using standard classification thresholds).\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    roc_curve, auc, precision_recall_curve\n",
        ")\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY CLASSES - DATA PROCESSING, METRICS, STATISTICS\n",
        "# ============================================================================\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"Handles data loading and preprocessing.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_preprocess(filepath):\n",
        "        \"\"\"\n",
        "        Load and preprocess customer churn dataset.\n",
        "        Steps: Load CSV → Remove ID → Convert TotalCharges to numeric →\n",
        "        Impute missing (median) → Encode categorical variables.\n",
        "        Returns: X (features), y (binary target), df (original data).\n",
        "        \"\"\"\n",
        "        df = pd.read_csv(filepath)\n",
        "        df = df.drop('customerID', axis=1)\n",
        "\n",
        "        # Convert TotalCharges to numeric, impute missing with median\n",
        "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "        df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
        "\n",
        "        X = df.drop('Churn', axis=1)\n",
        "        y = (df['Churn'] == 'Yes').astype(int)\n",
        "\n",
        "        # LabelEncoder: maps categorical values to integers\n",
        "        for col in X.select_dtypes(include='object').columns:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "        return X, y, df\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY CLASSES - METRICS CALCULATION\n",
        "# ============================================================================\n",
        "\n",
        "class MetricsCalculator:\n",
        "    \"\"\"Computes classification metrics for model evaluation.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_metrics(y_true, y_proba, y_pred, model_name, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Calculate classification metrics.\n",
        "        Returns: Dict with Accuracy, Precision, Recall, Specificity, F1,\n",
        "        ROC-AUC, MCC, Balanced Accuracy, and confusion matrix counts.\n",
        "        \"\"\"\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        roc_auc = roc_auc_score(y_true, y_proba)\n",
        "        mcc_denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "        mcc = ((tp * tn) - (fp * fn)) / mcc_denom if mcc_denom > 0 else 0\n",
        "        balanced_acc = (recall + specificity) / 2\n",
        "\n",
        "        return {\n",
        "            'Model': model_name, 'Threshold': threshold,\n",
        "            'Accuracy': accuracy, 'Precision': precision, 'Recall': recall,\n",
        "            'Specificity': specificity, 'F1_Score': f1, 'ROC_AUC': roc_auc,\n",
        "            'MCC': mcc, 'Balanced_Accuracy': balanced_acc,\n",
        "            'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_profit_function(y_true, y_proba, cost_matrix):\n",
        "        \"\"\"\n",
        "        Optimize decision threshold for maximum profit.\n",
        "        Tests 100 thresholds [0.05-0.95]. Returns: results list and optimal threshold.\n",
        "        Business logic: Different thresholds → Different TP/FP/FN/TN → Different profits.\n",
        "        \"\"\"\n",
        "        thresholds = np.linspace(0.05, 0.95, 100)\n",
        "        results = []\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_proba > threshold).astype(int)\n",
        "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "            # Calculate profit: TP*benefit + FP*cost + FN*cost + TN*zero\n",
        "            profit = (tp * cost_matrix['TP'] + fp * cost_matrix['FP'] +\n",
        "                     fn * cost_matrix['FN'] + tn * cost_matrix['TN'])\n",
        "\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            results.append({'threshold': threshold, 'profit': profit,\n",
        "                          'precision': precision, 'recall': recall, 'f1': f1,\n",
        "                          'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn})\n",
        "\n",
        "        max_profit = max([r['profit'] for r in results])\n",
        "        optimal_idx = [r['profit'] for r in results].index(max_profit)\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "        return results, optimal_threshold\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY CLASSES - STATISTICAL ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "class StatisticalAnalyzer:\n",
        "    \"\"\"Statistical significance testing and confidence intervals.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def bootstrap_auc(y_true, y_proba, n_iterations=1000, ci=95):\n",
        "        \"\"\"\n",
        "        Bootstrap resample ROC-AUC 1000x to estimate uncertainty.\n",
        "        Returns: Dict with AUC mean, std dev, and confidence interval bounds.\n",
        "        \"\"\"\n",
        "        bootstrap_aucs = []\n",
        "        n = len(y_true)\n",
        "\n",
        "        for _ in range(n_iterations):\n",
        "            indices = np.random.choice(n, n, replace=True)\n",
        "            y_true_boot = y_true.iloc[indices] if hasattr(y_true, 'iloc') else y_true[indices]\n",
        "            y_proba_boot = y_proba[indices]\n",
        "\n",
        "            if len(np.unique(y_true_boot)) == 2:\n",
        "                auc_boot = roc_auc_score(y_true_boot, y_proba_boot)\n",
        "                bootstrap_aucs.append(auc_boot)\n",
        "\n",
        "        auc_mean = np.mean(bootstrap_aucs)\n",
        "        auc_std = np.std(bootstrap_aucs)\n",
        "        lower = np.percentile(bootstrap_aucs, (100 - ci) / 2)\n",
        "        upper = np.percentile(bootstrap_aucs, 100 - (100 - ci) / 2)\n",
        "\n",
        "        return {'AUC_Mean': auc_mean, 'AUC_StdDev': auc_std,\n",
        "                'CI_Lower': lower, 'CI_Upper': upper}\n",
        "\n",
        "    @staticmethod\n",
        "    def paired_ttest_analysis(y_test, y_proba_hist, y_proba_hf):\n",
        "        \"\"\"\n",
        "        Paired t-test comparing F1-scores across 50 thresholds.\n",
        "        Tests if NN F1 differs significantly from HistGB F1 (p<0.05 = significant).\n",
        "        \"\"\"\n",
        "        thresholds = np.linspace(0.1, 0.9, 50)\n",
        "        hist_f1_scores = []\n",
        "        hf_f1_scores = []\n",
        "\n",
        "        for t in thresholds:\n",
        "            hist_pred_t = (y_proba_hist > t).astype(int)\n",
        "            hf_pred_t = (y_proba_hf > t).astype(int)\n",
        "            hist_f1_scores.append(f1_score(y_test, hist_pred_t, zero_division=0))\n",
        "            hf_f1_scores.append(f1_score(y_test, hf_pred_t, zero_division=0))\n",
        "\n",
        "        hist_f1_scores = np.array(hist_f1_scores)\n",
        "        hf_f1_scores = np.array(hf_f1_scores)\n",
        "        t_stat, p_value = stats.ttest_rel(hf_f1_scores, hist_f1_scores)\n",
        "\n",
        "        return {'HistGB_Mean_F1': hist_f1_scores.mean(),\n",
        "                'HistGB_Std_F1': hist_f1_scores.std(),\n",
        "                'NN_Mean_F1': hf_f1_scores.mean(),\n",
        "                'NN_Std_F1': hf_f1_scores.std(),\n",
        "                't_statistic': t_stat, 'p_value': p_value}\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS - PRINTING\n",
        "# ============================================================================\n",
        "\n",
        "def print_section_header(title):\n",
        "    \"\"\"Print formatted section header.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(title.center(100))\n",
        "    print(\"=\"*100)\n",
        "\n",
        "def print_subsection(subtitle):\n",
        "    \"\"\"Print formatted subsection header.\"\"\"\n",
        "    print(\"\\n\" + subtitle)\n",
        "    print(\"-\"*100)\n",
        "\n",
        "def print_metrics_table(metrics_df, columns):\n",
        "    \"\"\"Format and return metrics table as string.\"\"\"\n",
        "    metrics_display = metrics_df[columns].copy()\n",
        "    for col in columns:\n",
        "        if col != 'Model':\n",
        "            metrics_display[col] = metrics_display[col].apply(lambda x: f\"{x:.4f}\")\n",
        "    return metrics_display.to_string(index=False)\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN ANALYSIS PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main pipeline: Data load → Hyperparameter tuning → Metrics & statistics →\n",
        "    Profit optimization → Segmentation → Results summary → CSV reports.\n",
        "    \"\"\"\n",
        "\n",
        "    print_section_header(\"CUSTOMER CHURN PREDICTION ANALYSIS\")\n",
        "    print_section_header(\"Data Preparation and Feature Engineering\")\n",
        "\n",
        "    # STEP 1: DATA LOADING AND PREPROCESSING\n",
        "    X, y, df = DataProcessor.load_and_preprocess('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print_subsection(\"Dataset Summary\")\n",
        "    print(f\"Total observations: {len(df):,}\")\n",
        "    print(f\"Total features: {X.shape[1]}\")\n",
        "    print(f\"Target variable (Churn): Binary classification\")\n",
        "    print(f\"Churn rate: {y.mean()*100:.2f}%\")\n",
        "    print(f\"Class imbalance ratio: {(1-y.mean())/y.mean():.2f}:1\")\n",
        "    print(f\"Training set size: {len(X_train):,}\")\n",
        "    print(f\"Testing set size: {len(X_test):,}\")\n",
        "\n",
        "    # STEP 2: HYPERPARAMETER TUNING\n",
        "    print_section_header(\"Hyperparameter Optimization\")\n",
        "\n",
        "    hist_param_grid = {\n",
        "        'max_iter': [150, 200, 250],\n",
        "        'learning_rate': [0.05, 0.1, 0.15],\n",
        "        'max_depth': [8, 10, 12],\n",
        "        'l2_regularization': [0.5, 1.0, 1.5]\n",
        "    }\n",
        "\n",
        "    hf_param_grid = {\n",
        "        'hidden_layer_sizes': [(64, 32), (128, 64, 32), (128, 64, 32, 16)],\n",
        "        'learning_rate_init': [0.0005, 0.001, 0.002],\n",
        "        'alpha': [0.00005, 0.0001, 0.0002],\n",
        "        'max_iter': [250, 300, 350]\n",
        "    }\n",
        "\n",
        "    # Model registry: name, class, hyperparameter grid\n",
        "    models_config = [\n",
        "        ('HistGradientBoosting', HistGradientBoostingClassifier(min_samples_leaf=10, random_state=42), hist_param_grid),\n",
        "        ('Neural Network', MLPClassifier(early_stopping=True, validation_fraction=0.1, random_state=42, n_iter_no_change=20), hf_param_grid)\n",
        "    ]\n",
        "\n",
        "    trained_models = {}\n",
        "    predictions = {}\n",
        "\n",
        "    # Train both models with GridSearchCV (3-fold, 81 combinations each)\n",
        "    for model_name, model_class, param_grid in models_config:\n",
        "        print_subsection(f\"{model_name} Classifier Tuning\")\n",
        "\n",
        "        grid = GridSearchCV(model_class, param_grid, cv=3, n_jobs=-1, scoring='roc_auc', verbose=0)\n",
        "        grid.fit(X_train, y_train)\n",
        "        best_model = grid.best_estimator_\n",
        "\n",
        "        print(f\"Grid search completed: 81 parameter combinations evaluated\")\n",
        "        print(f\"Cross-validation strategy: 3-fold stratified\")\n",
        "        print(f\"Optimal ROC-AUC score: {grid.best_score_:.4f}\")\n",
        "        print(f\"Best parameters: {grid.best_params_}\")\n",
        "\n",
        "        y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "        y_pred = (y_proba > 0.5).astype(int)\n",
        "\n",
        "        trained_models[model_name] = best_model\n",
        "        predictions[model_name] = {'proba': y_proba, 'pred': y_pred}\n",
        "\n",
        "    # STEP 3: CLASSIFICATION METRICS - DEFAULT THRESHOLD 0.50\n",
        "    print_section_header(\"Classification Performance Metrics\")\n",
        "\n",
        "    calc = MetricsCalculator()\n",
        "    metrics_list = []\n",
        "\n",
        "    for model_name in ['HistGradientBoosting', 'Neural Network']:\n",
        "        metrics = calc.calculate_metrics(y_test, predictions[model_name]['proba'],\n",
        "                                        predictions[model_name]['pred'], model_name)\n",
        "        metrics_list.append(metrics)\n",
        "\n",
        "    metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "    print_subsection(\"Default Threshold (0.50) Performance Comparison\")\n",
        "    metrics_cols = ['Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1_Score', 'ROC_AUC', 'MCC']\n",
        "    print(print_metrics_table(metrics_df, metrics_cols))\n",
        "\n",
        "    for model_name in ['HistGradientBoosting', 'Neural Network']:\n",
        "        print_subsection(f\"Detailed Classification Report: {model_name}\")\n",
        "        print(classification_report(y_test, predictions[model_name]['pred'], target_names=['No Churn', 'Churn']))\n",
        "\n",
        "    # STEP 4: STATISTICAL SIGNIFICANCE TESTING\n",
        "    print_section_header(\"Statistical Significance Testing\")\n",
        "\n",
        "    analyzer = StatisticalAnalyzer()\n",
        "\n",
        "    print_subsection(\"Bootstrap Confidence Intervals for ROC-AUC (1000 iterations)\")\n",
        "    bootstrap_results = {}\n",
        "    for model_name in ['HistGradientBoosting', 'Neural Network']:\n",
        "        bootstrap = analyzer.bootstrap_auc(y_test, predictions[model_name]['proba'])\n",
        "        bootstrap_results[model_name] = bootstrap\n",
        "        print(f\"{model_name} AUC: {bootstrap['AUC_Mean']:.4f} ± {bootstrap['AUC_StdDev']:.4f}\")\n",
        "        print(f\"95% Confidence interval: [{bootstrap['CI_Lower']:.4f}, {bootstrap['CI_Upper']:.4f}]\")\n",
        "        print()\n",
        "\n",
        "    print_subsection(\"Paired t-Test: F1-Score Comparison Across 50 Thresholds\")\n",
        "    ttest_results = analyzer.paired_ttest_analysis(y_test, predictions['HistGradientBoosting']['proba'],\n",
        "                                                   predictions['Neural Network']['proba'])\n",
        "\n",
        "    print(f\"HistGradientBoost Mean F1: {ttest_results['HistGB_Mean_F1']:.4f} ± {ttest_results['HistGB_Std_F1']:.4f}\")\n",
        "    print(f\"Neural Network Mean F1: {ttest_results['NN_Mean_F1']:.4f} ± {ttest_results['NN_Std_F1']:.4f}\")\n",
        "    print(f\"t-statistic: {ttest_results['t_statistic']:.4f}\")\n",
        "    print(f\"p-value: {ttest_results['p_value']:.6f}\")\n",
        "\n",
        "    if ttest_results['p_value'] < 0.05:\n",
        "        print(f\"Result: Statistically significant (p < 0.05). NN shows superior performance.\")\n",
        "    else:\n",
        "        print(f\"Result: Not statistically significant (p >= 0.05).\")\n",
        "\n",
        "    print_subsection(\"Cross-Validation Score Analysis (5-fold)\")\n",
        "    for model_name in ['HistGradientBoosting', 'Neural Network']:\n",
        "        cv_scores = cross_val_score(trained_models[model_name], X_test, y_test, cv=5, scoring='roc_auc')\n",
        "        print(f\"{model_name} CV ROC-AUC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "        print(f\"Fold scores: {[f'{x:.4f}' for x in cv_scores]}\")\n",
        "        print()\n",
        "\n",
        "    # STEP 5: PROFIT OPTIMIZATION ANALYSIS\n",
        "    print_section_header(\"Profit Maximization Analysis\")\n",
        "\n",
        "    # Cost matrices reflect business reality: FN (lost customer) costs 14.57x more than FP (wasted contact)\n",
        "    BASIC_COSTS = {\n",
        "        'TP': 539.41,    # Retain churner: CLV ($2,331.36) - retention cost ($160) - salvage\n",
        "        'FP': -160.00,   # Wasted retention contact\n",
        "        'FN': -2331.36,  # Lost customer lifetime value\n",
        "        'TN': 0          # Correct non-churn prediction\n",
        "    }\n",
        "\n",
        "    SEGMENT_COSTS = {\n",
        "        'High': {'TP': 732.54, 'FP': -200.00, 'FN': -2331.36, 'TN': 0},    # Higher retention investment\n",
        "        'Medium': {'TP': 539.41, 'FP': -160.00, 'FN': -2331.36, 'TN': 0},   # Standard\n",
        "        'Low': {'TP': 228.14, 'FP': -5.00, 'FN': -2331.36, 'TN': 0}         # Light touch\n",
        "    }\n",
        "\n",
        "    print_subsection(\"Business Context and Cost Structure\")\n",
        "    print(f\"Customer Lifetime Value (CLV): $2,331.36\")\n",
        "    print(f\"Standard retention cost: $160.00\")\n",
        "    print(f\"TP value (retain churner): $539.41\")\n",
        "    print(f\"FP cost (wasted contact): -$160.00\")\n",
        "    print(f\"FN cost (lost customer): -$2,331.36\")\n",
        "    print(f\"Cost ratio (FN:FP): 14.57:1\")\n",
        "\n",
        "    print_subsection(\"Threshold Optimization Results (Basic Strategy)\")\n",
        "    basic_profit_results = {}\n",
        "    for model_name in ['HistGradientBoosting', 'Neural Network']:\n",
        "        results, opt_thresh = MetricsCalculator.generate_profit_function(\n",
        "            y_test, predictions[model_name]['proba'], BASIC_COSTS\n",
        "        )\n",
        "        max_profit = max([r['profit'] for r in results])\n",
        "        basic_profit_results[model_name] = {'profit': max_profit, 'threshold': opt_thresh, 'results': results}\n",
        "        print(f\"{model_name} optimal threshold: {opt_thresh:.3f}, Profit: ${max_profit:,.2f}\")\n",
        "\n",
        "    # STEP 6: SEGMENT-BASED STRATEGY\n",
        "    print_section_header(\"Segment-Based Strategy Analysis\")\n",
        "\n",
        "    def segment_analysis(y_proba, segment_costs, model_name):\n",
        "        \"\"\"\n",
        "        Segment customers by churn probability: High (>0.6), Medium (0.3-0.6), Low (≤0.3).\n",
        "        Optimize threshold separately for each segment with segment-specific costs.\n",
        "        \"\"\"\n",
        "        masks = {\n",
        "            'High': y_proba > 0.6,\n",
        "            'Medium': (y_proba > 0.3) & (y_proba <= 0.6),\n",
        "            'Low': y_proba <= 0.3\n",
        "        }\n",
        "\n",
        "        results = []\n",
        "        total_profit = 0\n",
        "\n",
        "        for seg_name in ['High', 'Medium', 'Low']:\n",
        "            seg_mask = masks[seg_name]\n",
        "            y_seg, y_proba_seg = y_test[seg_mask], y_proba[seg_mask]\n",
        "\n",
        "            if len(y_seg) < 10:  # Skip if segment too small\n",
        "                continue\n",
        "\n",
        "            seg_results, best_thresh = MetricsCalculator.generate_profit_function(\n",
        "                y_seg, y_proba_seg, segment_costs[seg_name]\n",
        "            )\n",
        "\n",
        "            seg_profit = max([r['profit'] for r in seg_results])\n",
        "            best_result = [r for r in seg_results if r['profit'] == seg_profit][0]\n",
        "\n",
        "            results.append({\n",
        "                'Model': model_name, 'Segment': seg_name,\n",
        "                'Sample_Count': seg_mask.sum(), 'Threshold': best_thresh,\n",
        "                'Profit': seg_profit, 'Precision': best_result['precision'],\n",
        "                'Recall': best_result['recall'], 'F1_Score': best_result['f1']\n",
        "            })\n",
        "            total_profit += seg_profit\n",
        "\n",
        "        return results, total_profit\n",
        "\n",
        "    all_seg_results = []\n",
        "    seg_profit_results = {}\n",
        "\n",
        "    for model_name in ['HistGradientBoosting', 'Neural Network']:\n",
        "        seg_results, seg_profit = segment_analysis(predictions[model_name]['proba'], SEGMENT_COSTS, model_name)\n",
        "        seg_profit_results[model_name] = seg_profit\n",
        "        all_seg_results.extend(seg_results)\n",
        "\n",
        "    print_subsection(\"Segment-Based Performance (Neural Network - Optimal Model)\")\n",
        "    nn_seg_results = [r for r in all_seg_results if r['Model'] == 'Neural Network']\n",
        "    for result in nn_seg_results:\n",
        "        print(f\"\\n{result['Segment']}-Risk Segment:\")\n",
        "        print(f\" Sample count: {result['Sample_Count']}\")\n",
        "        print(f\" Optimal threshold: {result['Threshold']:.3f}\")\n",
        "        print(f\" Precision: {result['Precision']:.4f}\")\n",
        "        print(f\" Recall: {result['Recall']:.4f}\")\n",
        "        print(f\" F1-Score: {result['F1_Score']:.4f}\")\n",
        "        print(f\" Profit: ${result['Profit']:,.2f}\")\n",
        "\n",
        "    # STEP 7: RESULTS SUMMARY\n",
        "    print_section_header(\"Summary of Results\")\n",
        "\n",
        "    strategy_summary = pd.DataFrame({\n",
        "        'Model': ['HistGradientBoost', 'HistGradientBoost', 'Neural Network', 'Neural Network'],\n",
        "        'Strategy': ['Basic', 'Segment-Based', 'Basic', 'Segment-Based'],\n",
        "        'Profit': [\n",
        "            f\"${basic_profit_results['HistGradientBoosting']['profit']:,.0f}\",\n",
        "            f\"${seg_profit_results['HistGradientBoosting']:,.0f}\",\n",
        "            f\"${basic_profit_results['Neural Network']['profit']:,.0f}\",\n",
        "            f\"${seg_profit_results['Neural Network']:,.0f}\"\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    print_subsection(\"Strategy Performance Comparison\")\n",
        "    print(strategy_summary.to_string(index=False))\n",
        "\n",
        "    print_subsection(\"Recommended Model and Strategy\")\n",
        "    best_profit = seg_profit_results['Neural Network']\n",
        "    baseline_profit = basic_profit_results['HistGradientBoosting']['profit']\n",
        "\n",
        "    print(f\"Best performing model: Neural Network (Segment-Based)\")\n",
        "    print(f\"Annual profit: ${best_profit:,.2f}\")\n",
        "    print(f\"Improvement vs. baseline: {((best_profit/baseline_profit) - 1)*100:.1f}%\")\n",
        "    print(f\"Tuning value gained: ${best_profit - basic_profit_results['Neural Network']['profit']:,.2f}\")\n",
        "\n",
        "    # STEP 8: GENERATE OUTPUT REPORTS\n",
        "    print_section_header(\"Report Generation\")\n",
        "\n",
        "    metrics_report = pd.DataFrame(metrics_list)\n",
        "    metrics_report.to_csv('classification_metrics_report.csv', index=False)\n",
        "    print(\"Generated: classification_metrics_report.csv\")\n",
        "\n",
        "    segment_df = pd.DataFrame(all_seg_results)\n",
        "    segment_df.to_csv('segment_analysis_metrics.csv', index=False)\n",
        "    print(\"Generated: segment_analysis_metrics.csv\")\n",
        "\n",
        "    strategy_df = pd.DataFrame({\n",
        "        'Model': strategy_summary['Model'],\n",
        "        'Strategy': strategy_summary['Strategy'],\n",
        "        'Profit': strategy_summary['Profit']\n",
        "    })\n",
        "    strategy_df.to_csv('strategy_performance.csv', index=False)\n",
        "    print(\"Generated: strategy_performance.csv\")\n",
        "\n",
        "    print_section_header(\"Analysis Complete\")\n",
        "    print(\"\\nAll analyses have been completed successfully.\")\n",
        "    print(\"Output files have been generated in the working directory.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EKsjYO0YG2il"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}