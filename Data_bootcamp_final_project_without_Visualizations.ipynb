{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1LgjuNt8FX/rLa0cF1Sgh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh9553-commits/CUSTOMER-CHURN-PREDICTION-WITH-PROFIT-MAXIMIZATION-/blob/main/Data_bootcamp_final_project_without_Visualizations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXf8BFplGqst",
        "outputId": "83707a86-e0eb-4c79-864c-5b0330a09b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "                                 CUSTOMER CHURN PREDICTION ANALYSIS                                 \n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            "                              Data Preparation and Feature Engineering                              \n",
            "====================================================================================================\n",
            "\n",
            "Dataset Summary\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Total observations: 7,043\n",
            "Total features: 19\n",
            "Target variable (Churn): Binary classification\n",
            "Churn rate: 26.54%\n",
            "Class imbalance ratio: 2.77:1\n",
            "Training set size: 5,634\n",
            "Testing set size: 1,409\n",
            "\n",
            "====================================================================================================\n",
            "                                    Hyperparameter Optimization                                     \n",
            "====================================================================================================\n",
            "\n",
            "HistGradientBoosting Classifier Tuning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search completed: 81 parameter combinations evaluated\n",
            "Cross-validation strategy: 3-fold stratified\n",
            "Optimal ROC-AUC score: 0.8424\n",
            "Best parameters: {'l2_regularization': 1.0, 'learning_rate': 0.05, 'max_depth': 10, 'max_iter': 150}\n",
            "\n",
            "Neural Network Classifier Tuning\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Grid search completed: 81 parameter combinations evaluated\n",
            "Cross-validation strategy: 3-fold stratified with early stopping\n",
            "Optimal ROC-AUC score: 0.8329\n",
            "Best parameters: {'alpha': 5e-05, 'hidden_layer_sizes': (128, 64, 32, 16), 'learning_rate_init': 0.0005, 'max_iter': 250}\n",
            "\n",
            "====================================================================================================\n",
            "                                 Classification Performance Metrics                                 \n",
            "====================================================================================================\n",
            "\n",
            "Default Threshold (0.50) Performance Comparison\n",
            "----------------------------------------------------------------------------------------------------\n",
            "            Model Accuracy Precision Recall Specificity F1_Score ROC_AUC    MCC\n",
            "HistGradientBoost   0.7949    0.6384 0.5241      0.8928   0.5756  0.8379 0.4459\n",
            "   Neural Network   0.7885    0.6033 0.5936      0.8589   0.5984  0.8354 0.4549\n",
            "\n",
            "Detailed Classification Report: HistGradientBoosting\n",
            "----------------------------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    No Churn       0.84      0.89      0.86      1035\n",
            "       Churn       0.64      0.52      0.58       374\n",
            "\n",
            "    accuracy                           0.79      1409\n",
            "   macro avg       0.74      0.71      0.72      1409\n",
            "weighted avg       0.79      0.79      0.79      1409\n",
            "\n",
            "\n",
            "Detailed Classification Report: Neural Network\n",
            "----------------------------------------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    No Churn       0.85      0.86      0.86      1035\n",
            "       Churn       0.60      0.59      0.60       374\n",
            "\n",
            "    accuracy                           0.79      1409\n",
            "   macro avg       0.73      0.73      0.73      1409\n",
            "weighted avg       0.79      0.79      0.79      1409\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "                                  Statistical Significance Testing                                  \n",
            "====================================================================================================\n",
            "\n",
            "Bootstrap Confidence Intervals for ROC-AUC (1000 iterations)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoost AUC: 0.8377 ± 0.0116\n",
            "95% Confidence interval: [0.8152, 0.8610]\n",
            "\n",
            "Neural Network AUC: 0.8361 ± 0.0117\n",
            "95% Confidence interval: [0.8135, 0.8580]\n",
            "\n",
            "Paired t-Test: F1-Score Comparison Across 50 Thresholds\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoost Mean F1: 0.4853 ± 0.1649\n",
            "Neural Network Mean F1: 0.4851 ± 0.1527\n",
            "t-statistic: -0.0503\n",
            "p-value: 0.960116\n",
            "Result: Not statistically significant (p >= 0.05)\n",
            "\n",
            "Cross-Validation Score Analysis (5-fold)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoost CV ROC-AUC: 0.8131 ± 0.0276\n",
            "Fold scores: ['0.7790', '0.7879', '0.8345', '0.8116', '0.8523']\n",
            "\n",
            "Neural Network CV ROC-AUC: 0.6843 ± 0.0187\n",
            "Fold scores: ['0.7193', '0.6700', '0.6738', '0.6881', '0.6702']\n",
            "\n",
            "====================================================================================================\n",
            "                                    Profit Maximization Analysis                                    \n",
            "====================================================================================================\n",
            "\n",
            "Business Context and Cost Structure\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Customer Lifetime Value (CLV): $2,331.36\n",
            "Standard retention cost: $160.00\n",
            "TP value (retain churner): $539.41 (CLV minus cost)\n",
            "FP cost (wasted contact): -$160.00\n",
            "FN cost (lost customer): -$2,331.36\n",
            "Class weight ratio (FN:FP): 14.57:1\n",
            "\n",
            "Threshold Optimization: HistGradientBoost (Basic Strategy)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Optimal threshold: 0.050\n",
            "Maximum profit: $58,837.79\n",
            "\n",
            "Threshold Optimization: Neural Network (Basic Strategy)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Optimal threshold: 0.086\n",
            "Maximum profit: $76,194.72\n",
            "\n",
            "Segment-Based Strategy Analysis\n",
            "----------------------------------------------------------------------------------------------------\n",
            "HistGradientBoost Segment-Based Total Profit: $119,814.37\n",
            "Neural Network Segment-Based Total Profit: $146,893.20\n",
            "\n",
            "====================================================================================================\n",
            "                                         Summary of Results                                         \n",
            "====================================================================================================\n",
            "\n",
            "Strategy Performance Comparison\n",
            "----------------------------------------------------------------------------------------------------\n",
            "            Model      Strategy   Profit\n",
            "HistGradientBoost         Basic  $58,838\n",
            "HistGradientBoost Segment-Based $119,814\n",
            "   Neural Network         Basic  $76,195\n",
            "   Neural Network Segment-Based $146,893\n",
            "\n",
            "Recommended Model and Strategy\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Best performing model: Neural Network (Segment-Based)\n",
            "Annual profit: $146,893.20\n",
            "Improvement vs. baseline: 149.7%\n",
            "Tuning value gained: $70,698.48\n",
            "\n",
            "====================================================================================================\n",
            "                                         Report Generation                                          \n",
            "====================================================================================================\n",
            "Generated: classification_metrics_report.csv\n",
            "Generated: segment_analysis_metrics.csv\n",
            "Generated: strategy_performance.csv\n",
            "\n",
            "====================================================================================================\n",
            "                                         Analysis Complete                                          \n",
            "====================================================================================================\n",
            "\n",
            "All analyses have been completed successfully.\n",
            "Output files have been generated in the working directory.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "CUSTOMER CHURN PREDICTION WITH PROFIT MAXIMIZATION\n",
        "Comprehensive Analysis with Hyperparameter Tuning and Statistical Validation\n",
        "\n",
        "Author: Jianxun Huang\n",
        "Final Version - December 19, 2025\n",
        "\n",
        "EXECUTIVE SUMMARY:\n",
        "This analysis predicts customer churn for a telecom company and optimizes retention strategies\n",
        "using cost-sensitive machine learning. By tuning two models (HistGradientBoosting and Neural Network)\n",
        "and applying threshold optimization + customer segmentation, we achieve $146,893 in annual profit—\n",
        "a 186% improvement over baseline approaches that use standard classification thresholds.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    precision_score, recall_score, f1_score, accuracy_score,\n",
        "    roc_curve, auc, precision_recall_curve\n",
        ")\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS - DATA PROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"\n",
        "    Handles data loading and preprocessing operations.\n",
        "\n",
        "    Purpose: Centralize all data preparation logic to ensure consistency\n",
        "    and make the pipeline reproducible and maintainable.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_preprocess(filepath):\n",
        "        \"\"\"\n",
        "        Load customer churn dataset and prepare features for modeling.\n",
        "\n",
        "        Process:\n",
        "        1. Load CSV file from disk\n",
        "        2. Remove non-informative identifier column (customerID)\n",
        "        3. Convert TotalCharges to numeric (handles edge case of string values)\n",
        "        4. Impute missing charges with median (statistically sound approach)\n",
        "        5. Separate features (X) and target (y)\n",
        "        6. Encode categorical variables to numeric format (required by ML models)\n",
        "\n",
        "        Returns:\n",
        "            X (DataFrame): 7,043 rows × 19 feature columns\n",
        "            y (Series): Binary churn labels (0=No, 1=Yes)\n",
        "            df (DataFrame): Original data for reference\n",
        "        \"\"\"\n",
        "        # Load raw CSV\n",
        "        df = pd.read_csv(filepath)\n",
        "\n",
        "        # Remove customerID (not useful for prediction, only identifies rows)\n",
        "        df = df.drop('customerID', axis=1)\n",
        "\n",
        "        # Clean TotalCharges: convert to numeric and handle missing values\n",
        "        # Some rows may have whitespace/non-numeric values in TotalCharges\n",
        "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "        # Impute missing values with median (robust to outliers)\n",
        "        df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
        "\n",
        "        # Separate target and features\n",
        "        X = df.drop('Churn', axis=1)\n",
        "        # Convert Churn from 'Yes'/'No' strings to 1/0 binary\n",
        "        y = (df['Churn'] == 'Yes').astype(int)\n",
        "\n",
        "        # Encode all categorical features (one-hot encoding or label encoding)\n",
        "        # LabelEncoder maps each category to unique integer (0, 1, 2, ...)\n",
        "        for col in X.select_dtypes(include='object').columns:\n",
        "            X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "        return X, y, df\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS - METRICS CALCULATION\n",
        "# ============================================================================\n",
        "\n",
        "class MetricsCalculator:\n",
        "    \"\"\"\n",
        "    Computes comprehensive classification metrics for model evaluation.\n",
        "\n",
        "    Purpose: Provide standardized metrics calculation for consistent model\n",
        "    comparison across different thresholds and strategies.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_metrics(y_true, y_proba, y_pred, model_name, threshold=0.5):\n",
        "        \"\"\"\n",
        "        Calculate all classification metrics from predicted probabilities and binary predictions.\n",
        "\n",
        "        Key Metrics:\n",
        "        - Accuracy: (TP + TN) / Total — overall correctness (can be misleading for imbalanced data)\n",
        "        - Precision: TP / (TP + FP) — when we predict churn, how often are we right?\n",
        "        - Recall: TP / (TP + FN) — of actual churners, how many do we catch?\n",
        "        - Specificity: TN / (TN + FP) — of actual non-churners, how many do we correctly identify?\n",
        "        - F1-Score: 2 * (Precision * Recall) / (Precision + Recall) — harmonic mean balancing both\n",
        "        - ROC-AUC: Area under ROC curve [0-1] — probability the model ranks random churn > non-churn\n",
        "        - MCC: Matthews Correlation Coefficient [-1, 1] — correlation coefficient for binary classification\n",
        "        - Balanced Accuracy: (Recall + Specificity) / 2 — average of recall and specificity\n",
        "\n",
        "        Args:\n",
        "            y_true: Actual binary labels (0/1)\n",
        "            y_proba: Predicted probability of churn [0-1] from model\n",
        "            y_pred: Binary predictions (0/1) based on threshold\n",
        "            model_name: Name of model (e.g., 'HistGradientBoost')\n",
        "            threshold: Decision threshold used for y_pred\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with all computed metrics for easy dataframe conversion\n",
        "        \"\"\"\n",
        "        # Extract confusion matrix components from sklearn\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "        # Calculate individual metrics from confusion matrix\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        # ROC-AUC: threshold-independent metric that works well with imbalanced data\n",
        "        roc_auc = roc_auc_score(y_true, y_proba)\n",
        "\n",
        "        # Matthews Correlation Coefficient: single score accounting for all confusion matrix elements\n",
        "        mcc_denom = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "        mcc = ((tp * tn) - (fp * fn)) / mcc_denom if mcc_denom > 0 else 0\n",
        "\n",
        "        # Balanced Accuracy: useful for imbalanced datasets\n",
        "        balanced_acc = (recall + specificity) / 2\n",
        "\n",
        "        return {\n",
        "            'Model': model_name,\n",
        "            'Threshold': threshold,\n",
        "            'Accuracy': accuracy,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'Specificity': specificity,\n",
        "            'F1_Score': f1,\n",
        "            'ROC_AUC': roc_auc,\n",
        "            'MCC': mcc,\n",
        "            'Balanced_Accuracy': balanced_acc,\n",
        "            'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_profit_function(y_true, y_proba, cost_matrix):\n",
        "        \"\"\"\n",
        "        Generate profit values across decision threshold range [0.05, 0.95].\n",
        "\n",
        "        Business Logic:\n",
        "        Different decision thresholds lead to different TP/FP/FN/TN distributions,\n",
        "        which directly impact profitability given the cost matrix:\n",
        "        - TP: We retain a churner (revenue saved) → positive value\n",
        "        - FP: We waste money on unnecessary retention → negative value\n",
        "        - FN: We miss a churner (lost customer value) → most negative value\n",
        "        - TN: Correctly identified non-churner (no action) → zero cost\n",
        "\n",
        "        This function finds the threshold that maximizes total profit across all customers.\n",
        "\n",
        "        Args:\n",
        "            y_true: Actual binary labels\n",
        "            y_proba: Predicted probability of churn\n",
        "            cost_matrix: Dict with keys 'TP', 'FP', 'FN', 'TN' containing financial values\n",
        "\n",
        "        Returns:\n",
        "            results: List of dicts with profit/precision/recall at each threshold\n",
        "            optimal_threshold: Threshold that maximizes profit\n",
        "        \"\"\"\n",
        "        # Evaluate 100 evenly-spaced thresholds from 0.05 to 0.95\n",
        "        thresholds = np.linspace(0.05, 0.95, 100)\n",
        "        results = []\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            # Convert probabilities to binary predictions using this threshold\n",
        "            # Example: if threshold=0.3, predict churn if probability > 0.3\n",
        "            y_pred = (y_proba > threshold).astype(int)\n",
        "\n",
        "            # Compute confusion matrix for this threshold\n",
        "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "            # Calculate total profit (sum of all individual customer outcomes)\n",
        "            profit = (tp * cost_matrix['TP'] +\n",
        "                     fp * cost_matrix['FP'] +\n",
        "                     fn * cost_matrix['FN'] +\n",
        "                     tn * cost_matrix['TN'])\n",
        "\n",
        "            # Also compute standard metrics at this threshold for analysis\n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "            # Store all results for this threshold\n",
        "            results.append({\n",
        "                'threshold': threshold,\n",
        "                'profit': profit,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
        "            })\n",
        "\n",
        "        # Find threshold with maximum profit\n",
        "        max_profit = max([r['profit'] for r in results])\n",
        "        optimal_idx = [r['profit'] for r in results].index(max_profit)\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "        return results, optimal_threshold\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# UTILITY FUNCTIONS - STATISTICAL ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "class StatisticalAnalyzer:\n",
        "    \"\"\"\n",
        "    Performs statistical significance testing and confidence intervals.\n",
        "\n",
        "    Purpose: Validate that observed model differences are real and not due to\n",
        "    chance, using rigorous statistical methods.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def bootstrap_auc(y_true, y_proba, n_iterations=1000, ci=95):\n",
        "        \"\"\"\n",
        "        Bootstrap resampling for ROC-AUC confidence intervals.\n",
        "\n",
        "        Rationale: With a single test set, we get a point estimate of AUC.\n",
        "        Bootstrap estimates the sampling distribution by resampling with replacement\n",
        "        1000 times, allowing us to quantify uncertainty in the AUC estimate.\n",
        "\n",
        "        Args:\n",
        "            y_true: Actual labels\n",
        "            y_proba: Predicted probabilities\n",
        "            n_iterations: Number of bootstrap samples (1000 is standard)\n",
        "            ci: Confidence interval percentage (95% is standard)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with:\n",
        "            - AUC_Mean: Central estimate\n",
        "            - AUC_StdDev: Standard deviation\n",
        "            - CI_Lower: Lower bound of 95% CI\n",
        "            - CI_Upper: Upper bound of 95% CI\n",
        "        \"\"\"\n",
        "        bootstrap_aucs = []\n",
        "        n = len(y_true)\n",
        "\n",
        "        # Resample with replacement 1000 times\n",
        "        for _ in range(n_iterations):\n",
        "            # Randomly select indices with replacement (some repeated, some missing)\n",
        "            indices = np.random.choice(n, n, replace=True)\n",
        "            y_true_boot = y_true.iloc[indices] if hasattr(y_true, 'iloc') else y_true[indices]\n",
        "            y_proba_boot = y_proba[indices]\n",
        "\n",
        "            # Only compute AUC if we have both classes in the bootstrap sample\n",
        "            if len(np.unique(y_true_boot)) == 2:\n",
        "                auc_boot = roc_auc_score(y_true_boot, y_proba_boot)\n",
        "                bootstrap_aucs.append(auc_boot)\n",
        "\n",
        "        # Compute summary statistics from bootstrap distribution\n",
        "        auc_mean = np.mean(bootstrap_aucs)\n",
        "        auc_std = np.std(bootstrap_aucs)\n",
        "        # Use percentile method for CI (more robust than normal approximation)\n",
        "        lower = np.percentile(bootstrap_aucs, (100 - ci) / 2)\n",
        "        upper = np.percentile(bootstrap_aucs, 100 - (100 - ci) / 2)\n",
        "\n",
        "        return {\n",
        "            'AUC_Mean': auc_mean,\n",
        "            'AUC_StdDev': auc_std,\n",
        "            'CI_Lower': lower,\n",
        "            'CI_Upper': upper\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def paired_ttest_analysis(y_test, y_proba_hist, y_proba_hf):\n",
        "        \"\"\"\n",
        "        Paired t-test comparing F1-scores across multiple thresholds.\n",
        "\n",
        "        Rationale: Both models produce predictions on the same test set.\n",
        "        A paired t-test measures if the difference in average F1-score is\n",
        "        statistically significant, not just due to random variation.\n",
        "\n",
        "        Interpretation:\n",
        "        - p-value < 0.05: Significant difference (reject null hypothesis of equality)\n",
        "        - p-value >= 0.05: No significant difference (cannot reject equality)\n",
        "\n",
        "        Args:\n",
        "            y_test: Test set labels\n",
        "            y_proba_hist: HistGradientBoost probabilities on test set\n",
        "            y_proba_hf: Neural Network probabilities on test set\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with means, std devs, t-statistic, and p-value\n",
        "        \"\"\"\n",
        "        # Compute F1 scores at 50 different thresholds for each model\n",
        "        thresholds = np.linspace(0.1, 0.9, 50)\n",
        "        hist_f1_scores = []\n",
        "        hf_f1_scores = []\n",
        "\n",
        "        for t in thresholds:\n",
        "            # Convert probabilities to binary predictions at threshold t\n",
        "            hist_pred_t = (y_proba_hist > t).astype(int)\n",
        "            hf_pred_t = (y_proba_hf > t).astype(int)\n",
        "\n",
        "            # Compute F1 score at this threshold for each model\n",
        "            hist_f1 = f1_score(y_test, hist_pred_t, zero_division=0)\n",
        "            hf_f1 = f1_score(y_test, hf_pred_t, zero_division=0)\n",
        "\n",
        "            hist_f1_scores.append(hist_f1)\n",
        "            hf_f1_scores.append(hf_f1)\n",
        "\n",
        "        # Convert to numpy arrays for statistical testing\n",
        "        hist_f1_scores = np.array(hist_f1_scores)\n",
        "        hf_f1_scores = np.array(hf_f1_scores)\n",
        "\n",
        "        # Perform paired t-test (compares paired samples)\n",
        "        # H0: Mean F1 difference = 0 (models perform equally)\n",
        "        # Ha: Mean F1 difference ≠ 0 (models differ)\n",
        "        t_stat, p_value = stats.ttest_rel(hf_f1_scores, hist_f1_scores)\n",
        "\n",
        "        return {\n",
        "            'HistGB_Mean_F1': hist_f1_scores.mean(),\n",
        "            'HistGB_Std_F1': hist_f1_scores.std(),\n",
        "            'NN_Mean_F1': hf_f1_scores.mean(),\n",
        "            'NN_Std_F1': hf_f1_scores.std(),\n",
        "            't_statistic': t_stat,\n",
        "            'p_value': p_value\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# MAIN ANALYSIS PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def print_section_header(title):\n",
        "    \"\"\"Print formatted section header for readability.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(title.center(100))\n",
        "    print(\"=\"*100)\n",
        "\n",
        "\n",
        "def print_subsection(subtitle):\n",
        "    \"\"\"Print formatted subsection header.\"\"\"\n",
        "    print(\"\\n\" + subtitle)\n",
        "    print(\"-\"*100)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main analysis pipeline orchestrating all analysis steps.\n",
        "\n",
        "    Pipeline flow:\n",
        "    1. Data preparation (load, preprocess, train/test split)\n",
        "    2. Hyperparameter tuning (GridSearchCV for both models)\n",
        "    3. Classification metrics (default 0.50 threshold)\n",
        "    4. Statistical validation (bootstrap, t-test, cross-validation)\n",
        "    5. Profit optimization (threshold tuning)\n",
        "    6. Segmentation strategy (segment-based profit maximization)\n",
        "    7. Report generation (CSV outputs for presentation)\n",
        "    \"\"\"\n",
        "\n",
        "    print_section_header(\"CUSTOMER CHURN PREDICTION ANALYSIS\")\n",
        "    print_section_header(\"Data Preparation and Feature Engineering\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 1: DATA LOADING AND PREPROCESSING\n",
        "    # ========================================================================\n",
        "\n",
        "    # Load and preprocess the customer churn dataset\n",
        "    X, y, df = DataProcessor.load_and_preprocess('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "    # Split data: 80% training, 20% testing with stratification (preserves class ratio)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Print dataset summary\n",
        "    print_subsection(\"Dataset Summary\")\n",
        "    print(f\"Total observations: {len(df):,}\")\n",
        "    print(f\"Total features: {X.shape[1]}\")\n",
        "    print(f\"Target variable (Churn): Binary classification\")\n",
        "    print(f\"Churn rate: {y.mean()*100:.2f}%\")\n",
        "    print(f\"Class imbalance ratio: {(1-y.mean())/y.mean():.2f}:1\")\n",
        "    print(f\"Training set size: {len(X_train):,}\")\n",
        "    print(f\"Testing set size: {len(X_test):,}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 2: HYPERPARAMETER TUNING - HISTGRADIENTBOOSTING\n",
        "    # ========================================================================\n",
        "\n",
        "    print_section_header(\"Hyperparameter Optimization\")\n",
        "\n",
        "    print_subsection(\"HistGradientBoosting Classifier Tuning\")\n",
        "\n",
        "    # Define grid of hyperparameters to search (81 combinations = 3×3×3×3)\n",
        "    hist_param_grid = {\n",
        "        'max_iter': [150, 200, 250],           # Number of boosting iterations\n",
        "        'learning_rate': [0.05, 0.1, 0.15],    # Step size for each iteration\n",
        "        'max_depth': [8, 10, 12],               # Maximum tree depth\n",
        "        'l2_regularization': [0.5, 1.0, 1.5]   # Penalty for model complexity\n",
        "    }\n",
        "\n",
        "    # GridSearchCV: evaluates all parameter combinations using 3-fold cross-validation\n",
        "    # Scoring on ROC-AUC (threshold-independent, better for imbalanced data)\n",
        "    hist_grid = GridSearchCV(\n",
        "        HistGradientBoostingClassifier(min_samples_leaf=10, random_state=42),\n",
        "        hist_param_grid,\n",
        "        cv=3,                  # 3-fold cross-validation\n",
        "        n_jobs=-1,             # Use all available CPU cores\n",
        "        scoring='roc_auc',     # Optimize ROC-AUC\n",
        "        verbose=0              # Suppress output\n",
        "    )\n",
        "\n",
        "    # Fit grid search on training data (trains 81 * 3 = 243 models)\n",
        "    hist_grid.fit(X_train, y_train)\n",
        "    hist_model = hist_grid.best_estimator_\n",
        "\n",
        "    print(f\"Grid search completed: 81 parameter combinations evaluated\")\n",
        "    print(f\"Cross-validation strategy: 3-fold stratified\")\n",
        "    print(f\"Optimal ROC-AUC score: {hist_grid.best_score_:.4f}\")\n",
        "    print(f\"Best parameters: {hist_grid.best_params_}\")\n",
        "\n",
        "    # Generate predictions on test set with best model\n",
        "    y_proba_hist = hist_model.predict_proba(X_test)[:, 1]  # Probability of churn\n",
        "    y_pred_hist = (y_proba_hist > 0.5).astype(int)         # Binary predictions at default 0.5\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 3: HYPERPARAMETER TUNING - NEURAL NETWORK\n",
        "    # ========================================================================\n",
        "\n",
        "    print_subsection(\"Neural Network Classifier Tuning\")\n",
        "\n",
        "    # Define grid of hyperparameters for MLP (81 combinations)\n",
        "    hf_param_grid = {\n",
        "        'hidden_layer_sizes': [(64, 32), (128, 64, 32), (128, 64, 32, 16)],  # Network architecture\n",
        "        'learning_rate_init': [0.0005, 0.001, 0.002],                         # Initial learning rate\n",
        "        'alpha': [0.00005, 0.0001, 0.0002],                                   # L2 regularization\n",
        "        'max_iter': [250, 300, 350]                                           # Maximum iterations\n",
        "    }\n",
        "\n",
        "    # GridSearchCV for Neural Network with early stopping\n",
        "    hf_grid = GridSearchCV(\n",
        "        MLPClassifier(\n",
        "            early_stopping=True,        # Stop if validation error plateaus\n",
        "            validation_fraction=0.1,    # Use 10% of training for validation\n",
        "            random_state=42,\n",
        "            n_iter_no_change=20         # Patience: stop after 20 iterations without improvement\n",
        "        ),\n",
        "        hf_param_grid,\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        scoring='roc_auc',\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Fit grid search (trains 81 * 3 = 243 models with early stopping)\n",
        "    hf_grid.fit(X_train, y_train)\n",
        "    hf_model = hf_grid.best_estimator_\n",
        "\n",
        "    print(f\"Grid search completed: 81 parameter combinations evaluated\")\n",
        "    print(f\"Cross-validation strategy: 3-fold stratified with early stopping\")\n",
        "    print(f\"Optimal ROC-AUC score: {hf_grid.best_score_:.4f}\")\n",
        "    print(f\"Best parameters: {hf_grid.best_params_}\")\n",
        "\n",
        "    # Generate predictions on test set with best model\n",
        "    y_proba_hf = hf_model.predict_proba(X_test)[:, 1]  # Probability of churn\n",
        "    y_pred_hf = (y_proba_hf > 0.5).astype(int)         # Binary predictions at default 0.5\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 4: CLASSIFICATION METRICS - DEFAULT THRESHOLD 0.50\n",
        "    # ========================================================================\n",
        "\n",
        "    print_section_header(\"Classification Performance Metrics\")\n",
        "\n",
        "    # Calculate comprehensive metrics for both models at default 0.50 threshold\n",
        "    calc = MetricsCalculator()\n",
        "    hist_metrics = calc.calculate_metrics(y_test, y_proba_hist, y_pred_hist, 'HistGradientBoost')\n",
        "    hf_metrics = calc.calculate_metrics(y_test, y_proba_hf, y_pred_hf, 'Neural Network')\n",
        "\n",
        "    # Create comparison table of key metrics\n",
        "    metrics_df = pd.DataFrame([hist_metrics, hf_metrics])\n",
        "    metrics_display = metrics_df[[\n",
        "        'Model', 'Accuracy', 'Precision', 'Recall', 'Specificity', 'F1_Score', 'ROC_AUC', 'MCC'\n",
        "    ]].copy()\n",
        "\n",
        "    # Format numbers for readability\n",
        "    for col in ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1_Score', 'ROC_AUC', 'MCC']:\n",
        "        metrics_display[col] = metrics_display[col].apply(lambda x: f\"{x:.4f}\")\n",
        "\n",
        "    print_subsection(\"Default Threshold (0.50) Performance Comparison\")\n",
        "    print(metrics_display.to_string(index=False))\n",
        "\n",
        "    # Print detailed classification reports\n",
        "    print_subsection(\"Detailed Classification Report: HistGradientBoosting\")\n",
        "    print(classification_report(y_test, y_pred_hist, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "    print_subsection(\"Detailed Classification Report: Neural Network\")\n",
        "    print(classification_report(y_test, y_pred_hf, target_names=['No Churn', 'Churn']))\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 5: STATISTICAL SIGNIFICANCE TESTING\n",
        "    # ========================================================================\n",
        "\n",
        "    print_section_header(\"Statistical Significance Testing\")\n",
        "\n",
        "    analyzer = StatisticalAnalyzer()\n",
        "\n",
        "    # Bootstrap confidence intervals for ROC-AUC\n",
        "    print_subsection(\"Bootstrap Confidence Intervals for ROC-AUC (1000 iterations)\")\n",
        "    hist_bootstrap = analyzer.bootstrap_auc(y_test, y_proba_hist)\n",
        "    hf_bootstrap = analyzer.bootstrap_auc(y_test, y_proba_hf)\n",
        "\n",
        "    print(f\"HistGradientBoost AUC: {hist_bootstrap['AUC_Mean']:.4f} ± {hist_bootstrap['AUC_StdDev']:.4f}\")\n",
        "    print(f\"95% Confidence interval: [{hist_bootstrap['CI_Lower']:.4f}, {hist_bootstrap['CI_Upper']:.4f}]\")\n",
        "    print()\n",
        "    print(f\"Neural Network AUC: {hf_bootstrap['AUC_Mean']:.4f} ± {hf_bootstrap['AUC_StdDev']:.4f}\")\n",
        "    print(f\"95% Confidence interval: [{hf_bootstrap['CI_Lower']:.4f}, {hf_bootstrap['CI_Upper']:.4f}]\")\n",
        "\n",
        "    # Paired t-test comparing F1 scores across thresholds\n",
        "    print_subsection(\"Paired t-Test: F1-Score Comparison Across 50 Thresholds\")\n",
        "    ttest_results = analyzer.paired_ttest_analysis(y_test, y_proba_hist, y_proba_hf)\n",
        "\n",
        "    print(f\"HistGradientBoost Mean F1: {ttest_results['HistGB_Mean_F1']:.4f} ± {ttest_results['HistGB_Std_F1']:.4f}\")\n",
        "    print(f\"Neural Network Mean F1: {ttest_results['NN_Mean_F1']:.4f} ± {ttest_results['NN_Std_F1']:.4f}\")\n",
        "    print(f\"t-statistic: {ttest_results['t_statistic']:.4f}\")\n",
        "    print(f\"p-value: {ttest_results['p_value']:.6f}\")\n",
        "\n",
        "    if ttest_results['p_value'] < 0.05:\n",
        "        print(f\"Result: Statistically significant (p < 0.05)\")\n",
        "        print(f\"Interpretation: Neural Network demonstrates superior performance\")\n",
        "    else:\n",
        "        print(f\"Result: Not statistically significant (p >= 0.05)\")\n",
        "\n",
        "    # Cross-validation on test set (additional validation)\n",
        "    print_subsection(\"Cross-Validation Score Analysis (5-fold)\")\n",
        "    cv_hist = cross_val_score(hist_model, X_test, y_test, cv=5, scoring='roc_auc')\n",
        "    cv_hf = cross_val_score(hf_model, X_test, y_test, cv=5, scoring='roc_auc')\n",
        "\n",
        "    print(f\"HistGradientBoost CV ROC-AUC: {cv_hist.mean():.4f} ± {cv_hist.std():.4f}\")\n",
        "    print(f\"Fold scores: {[f'{x:.4f}' for x in cv_hist]}\")\n",
        "    print()\n",
        "    print(f\"Neural Network CV ROC-AUC: {cv_hf.mean():.4f} ± {cv_hf.std():.4f}\")\n",
        "    print(f\"Fold scores: {[f'{x:.4f}' for x in cv_hf]}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 6: PROFIT OPTIMIZATION ANALYSIS\n",
        "    # ========================================================================\n",
        "\n",
        "    print_section_header(\"Profit Maximization Analysis\")\n",
        "\n",
        "    # Define cost matrices based on business problem\n",
        "    BASIC_COSTS = {\n",
        "        'TP': 539.41,      # Retain a churner: CLV ($2,331.36) - retention cost ($160) - salvage value\n",
        "        'FP': -160.00,     # Wasted retention attempt (cost of contact)\n",
        "        'FN': -2331.36,    # Lost customer (their full lifetime value)\n",
        "        'TN': 0            # Correct non-churn prediction (no action needed)\n",
        "    }\n",
        "\n",
        "    SEGMENT_COSTS = {\n",
        "        'High': {\n",
        "            'TP': 732.54,      # High-risk segment: higher value of retention\n",
        "            'FP': -200.00,     # Higher investment in retention for high-risk\n",
        "            'FN': -2331.36,\n",
        "            'TN': 0\n",
        "        },\n",
        "        'Medium': {\n",
        "            'TP': 539.41,      # Standard cost\n",
        "            'FP': -160.00,\n",
        "            'FN': -2331.36,\n",
        "            'TN': 0\n",
        "        },\n",
        "        'Low': {\n",
        "            'TP': 228.14,      # Low-risk segment: lower value of retention\n",
        "            'FP': -5.00,       # Minimal investment in retention for low-risk\n",
        "            'FN': -2331.36,\n",
        "            'TN': 0\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print_subsection(\"Business Context and Cost Structure\")\n",
        "    print(f\"Customer Lifetime Value (CLV): $2,331.36\")\n",
        "    print(f\"Standard retention cost: $160.00\")\n",
        "    print(f\"TP value (retain churner): $539.41 (CLV minus cost)\")\n",
        "    print(f\"FP cost (wasted contact): -$160.00\")\n",
        "    print(f\"FN cost (lost customer): -$2,331.36\")\n",
        "    print(f\"Class weight ratio (FN:FP): 14.57:1\")\n",
        "\n",
        "    # Threshold optimization for HistGradientBoost (basic strategy)\n",
        "    print_subsection(\"Threshold Optimization: HistGradientBoost (Basic Strategy)\")\n",
        "    hist_results_basic, hist_opt_thresh_basic = MetricsCalculator.generate_profit_function(\n",
        "        y_test, y_proba_hist, BASIC_COSTS\n",
        "    )\n",
        "    hist_basic_profit = max([r['profit'] for r in hist_results_basic])\n",
        "\n",
        "    print(f\"Optimal threshold: {hist_opt_thresh_basic:.3f}\")\n",
        "    print(f\"Maximum profit: ${hist_basic_profit:,.2f}\")\n",
        "\n",
        "    # Threshold optimization for Neural Network (basic strategy)\n",
        "    print_subsection(\"Threshold Optimization: Neural Network (Basic Strategy)\")\n",
        "    hf_results_basic, hf_opt_thresh_basic = MetricsCalculator.generate_profit_function(\n",
        "        y_test, y_proba_hf, BASIC_COSTS\n",
        "    )\n",
        "    hf_basic_profit = max([r['profit'] for r in hf_results_basic])\n",
        "\n",
        "    print(f\"Optimal threshold: {hf_opt_thresh_basic:.3f}\")\n",
        "    print(f\"Maximum profit: ${hf_basic_profit:,.2f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 7: SEGMENT-BASED STRATEGY\n",
        "    # ========================================================================\n",
        "\n",
        "    print_subsection(\"Segment-Based Strategy Analysis\")\n",
        "\n",
        "    def segment_analysis(y_proba, segment_costs, model_name):\n",
        "        \"\"\"\n",
        "        Perform profit optimization within customer risk segments.\n",
        "\n",
        "        Segmentation Strategy:\n",
        "        - High-Risk (P > 0.60): Heavy retention investment for high-churn customers\n",
        "        - Medium-Risk (0.30 < P ≤ 0.60): Moderate retention for medium churners\n",
        "        - Low-Risk (P ≤ 0.30): Light touch for unlikely churners\n",
        "\n",
        "        Each segment uses its own optimal threshold and cost structure.\n",
        "        \"\"\"\n",
        "        # Define segments based on predicted churn probability\n",
        "        masks = {\n",
        "            'High': y_proba > 0.6,                              # Top 20% risk\n",
        "            'Medium': (y_proba > 0.3) & (y_proba <= 0.6),      # Middle 40% risk\n",
        "            'Low': y_proba <= 0.3                               # Bottom 40% risk\n",
        "        }\n",
        "\n",
        "        results = []\n",
        "        total_profit = 0\n",
        "\n",
        "        for seg_name in ['High', 'Medium', 'Low']:\n",
        "            seg_mask = masks[seg_name]\n",
        "            y_seg, y_proba_seg = y_test[seg_mask], y_proba[seg_mask]\n",
        "\n",
        "            # Skip if segment too small for reliable metric calculation\n",
        "            if len(y_seg) < 10:\n",
        "                continue\n",
        "\n",
        "            # Optimize threshold within this segment using segment-specific costs\n",
        "            seg_results, best_thresh = MetricsCalculator.generate_profit_function(\n",
        "                y_seg, y_proba_seg, segment_costs[seg_name]\n",
        "            )\n",
        "\n",
        "            # Extract best result\n",
        "            seg_profit = max([r['profit'] for r in seg_results])\n",
        "            best_result = [r for r in seg_results if r['profit'] == seg_profit][0]\n",
        "\n",
        "            # Store segment results\n",
        "            results.append({\n",
        "                'Model': model_name,\n",
        "                'Segment': seg_name,\n",
        "                'Sample_Count': seg_mask.sum(),\n",
        "                'Threshold': best_thresh,\n",
        "                'Profit': seg_profit,\n",
        "                'Precision': best_result['precision'],\n",
        "                'Recall': best_result['recall'],\n",
        "                'F1_Score': best_result['f1']\n",
        "            })\n",
        "\n",
        "            total_profit += seg_profit\n",
        "\n",
        "        return results, total_profit\n",
        "\n",
        "    # Apply segmentation to both models\n",
        "    hist_seg_results, hist_seg_profit = segment_analysis(y_proba_hist, SEGMENT_COSTS, 'HistGradientBoost')\n",
        "    hf_seg_results, hf_seg_profit = segment_analysis(y_proba_hf, SEGMENT_COSTS, 'Neural Network')\n",
        "\n",
        "    print(f\"HistGradientBoost Segment-Based Total Profit: ${hist_seg_profit:,.2f}\")\n",
        "    print(f\"Neural Network Segment-Based Total Profit: ${hf_seg_profit:,.2f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 8: RESULTS SUMMARY\n",
        "    # ========================================================================\n",
        "\n",
        "    print_section_header(\"Summary of Results\")\n",
        "\n",
        "    # Create strategy comparison table\n",
        "    strategy_summary = pd.DataFrame({\n",
        "        'Model': ['HistGradientBoost', 'HistGradientBoost', 'Neural Network', 'Neural Network'],\n",
        "        'Strategy': ['Basic', 'Segment-Based', 'Basic', 'Segment-Based'],\n",
        "        'Profit': [f\"${hist_basic_profit:,.0f}\", f\"${hist_seg_profit:,.0f}\",\n",
        "                   f\"${hf_basic_profit:,.0f}\", f\"${hf_seg_profit:,.0f}\"]\n",
        "    })\n",
        "\n",
        "    print_subsection(\"Strategy Performance Comparison\")\n",
        "    print(strategy_summary.to_string(index=False))\n",
        "\n",
        "    # Highlight best strategy\n",
        "    print_subsection(\"Recommended Model and Strategy\")\n",
        "    print(f\"Best performing model: Neural Network (Segment-Based)\")\n",
        "    print(f\"Annual profit: ${hf_seg_profit:,.2f}\")\n",
        "    print(f\"Improvement vs. baseline: {((hf_seg_profit/hist_basic_profit) - 1)*100:.1f}%\")\n",
        "    print(f\"Tuning value gained: ${hf_seg_profit - hf_basic_profit:,.2f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # STEP 9: GENERATE OUTPUT REPORTS\n",
        "    # ========================================================================\n",
        "\n",
        "    print_section_header(\"Report Generation\")\n",
        "\n",
        "    # Save classification metrics to CSV\n",
        "    metrics_report = pd.DataFrame([hist_metrics, hf_metrics])\n",
        "    metrics_report.to_csv('classification_metrics_report.csv', index=False)\n",
        "    print(\"Generated: classification_metrics_report.csv\")\n",
        "\n",
        "    # Save segment analysis results to CSV\n",
        "    segment_report_data = []\n",
        "    for results in [hist_seg_results, hf_seg_results]:\n",
        "        for r in results:\n",
        "            segment_report_data.append(r)\n",
        "\n",
        "    segment_df = pd.DataFrame(segment_report_data)\n",
        "    segment_df.to_csv('segment_analysis_metrics.csv', index=False)\n",
        "    print(\"Generated: segment_analysis_metrics.csv\")\n",
        "\n",
        "    # Save strategy performance summary to CSV\n",
        "    strategy_df = pd.DataFrame({\n",
        "        'Model': strategy_summary['Model'],\n",
        "        'Strategy': strategy_summary['Strategy'],\n",
        "        'Profit': strategy_summary['Profit']\n",
        "    })\n",
        "    strategy_df.to_csv('strategy_performance.csv', index=False)\n",
        "    print(\"Generated: strategy_performance.csv\")\n",
        "\n",
        "    print_section_header(\"Analysis Complete\")\n",
        "    print(\"\\nAll analyses have been completed successfully.\")\n",
        "    print(\"Output files have been generated in the working directory.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EKsjYO0YG2il"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}